# Awsome-Time-Series-Foundation-Model

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

<p align="center">
  <img width="300" src="https://i.imgur.com/Ky2jxnj.png" "Awesome!">
</p>

An up-to-date & curated list of Awsome Time Series Foundation Model papers, methods & resources.

## Acknowledgment

Many thanks to the useful publications and repos: [Jingdong Wang](https://github.com/jindongwang), [Awesome-Deep-Vision](https://github.com/kjw0612/awesome-deep-vision), [Awesome-Deep-Learning-Papers](https://github.com/terryum/awesome-deep-learning-papers), [Awesome-Self-Supervised-Learning](https://github.com/jason718/awesome-self-supervised-learning), [Awesome-Semi-Supervised-Learning](https://github.com/yassouali/awesome-semi-supervised-learning), [Awesome-Human-Activity-Recognition
](https://github.com/haoranD/Awesome-Human-Activity-Recognition/) and [Awesome-Crowd-Counting](https://github.com/gjy3035/Awesome-Crowd-Counting#datasets).

## Contributing
<p align="center">
  <img src="http://cdn1.sportngin.com/attachments/news_article/7269/5172/needyou_small.jpg" alt="We Need You!">
</p>

Please feel free to contribute this list.


## Conferences, Journals and Workshops
- IJCAI, ACM MultiMedia, AAAI, KDD, ICDM, TKDE, TIP, TNNLS, TPAMI, TMM, Pattern Recognition, AI, Nature Communication, Nature Digital Medicine, ICPR, Sensors, Ubicomp(IMWUT Journal)

## Datasets

- Capture-24 [[**link**](https://github.com/OxWearables/capture24)]

## Tools

## Other related tasks

## Potential Research Direction

## Papers

### Surveys & Overview

### 2024

- <a name="TSPTM"></a> **[TSPTM]** A Survey on Time-Series Pre-Trained Models: A Survey (**IEEE Transactions on Knowledge and Data Engineering**) [[paper](https://arxiv.org/abs/2305.10716)][[code](https://github.com/qianlima-lab/time-series-ptms)]

- <a name="Time-LLM"></a> **[Time-LLM]** Time-LLM: Time series forecasting by reprogramming large language models: (**12th Int. Conf. Learn. Representations**)[[paper](https://arxiv.org/pdf/2310.01728)][[code](https://github.com/KimMeen/Time-LLM)]

- <a name="MTP-Flow"></a> **[MTP-Flow]** Masked token enabled pre-training: A task-agnostic approach for understanding complex traffic flow: (**IEEE Transactions on Mobile Computing**)[[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10505023)][[code](https://github.com/Xiao-Di/TSSN)]

- <a name="TEMPO"></a> **[TEMPO]** TEMPO: Prompt-based generative pre-trained transformer for time series forecasting: (**ICLR 2024**)[[paper](https://arxiv.org/pdf/2310.04948)][[code](https://github.com/DC-research/TEMPO)]

- <a name="iTransformer"></a> **[iTransformer]** Inverted transformers are effective for time series forecasting: (**ICLR 2024**)[[paper](https://arxiv.org/pdf/2310.06625)][[code](https://github.com/thuml/iTransformer)]

### 2023

- <a name="PatchTST"></a> **[PatchTST]** A time series is worth 64 words: Long-term forecasting with transformers: (**ICLR 2023**)[[paper](https://arxiv.org/pdf/2211.14730)][[code](https://github.com/PatchTST/PatchTST)]

- <a name="TimesNet"></a> **[TimesNet]** TimesNet: Temporal 2D-variation modeling for general time series analysis: (**ICLR 2023**)[[paper](https://arxiv.org/pdf/2210.02186)][[code](https://github.com/thuml/TimesNet)]

- <a name="OFa"></a> **[OFa]** One fits all: Power general time series analysis by pretrained LM: (**NeurIPS 2023**)[[paper](https://arxiv.org/pdf/2302.11939)][[code](https://github.com/DAMO-DI-ML/NeurIPS2023-One-Fits-All)]

- <a name="D-Linear"></a> **[D-Linear]** Are transformers effective for time series forecasting?: (**AAAI 2023**)[[paper](https://arxiv.org/pdf/2205.13504)][[code](https://github.com/cure-lab/LTSF-Linear)]

### 2022

- <a name="FEDformer"></a>  **[FEDformer]** FEDformer: Frequency enhanced decomposed transformer for long-term series forecasting: (**IEEE International Conference on Data Mining**)[[paper](https://arxiv.org/pdf/2201.12740)][[code](https://github.com/MAZiqing/FEDformer)]

- <a name="CR-Transformer"></a>  **[CR-Transformer]** Cross reconstruction transformer for self-supervised time series representation learning: (**ICML 2021**)[[paper](https://arxiv.org/pdf/2205.09928)][[code](https://github.com/BobZwr/Cross-Reconstruction-Transformer)]

- <a name="TS2Vec"></a>  **[TS2Vec]** TS2Vec: Towards universal representation of time series: (**ICDM 2021**)[[paper](https://arxiv.org/pdf/2106.10466v2)][[code](https://github.com/zhihanyue/ts2vec)]

- <a name="CoST"></a>  **[CoST]** CoST: Contrastive learning of disentangled seasonal-trend representations for time series forecasting: (**ICLR 2022**)[[paper](https://arxiv.org/pdf/2202.01575)][[code](https://github.com/salesforce/CoST)]

### 2021

- <a name="TSDA-SASA"></a>  **[TSDA-SASA]** Time series domain adaptation via sparse associative structure alignment: (**AAAI Conf. Artif. Intell**)[[Paper](https://arxiv.org/abs/2012.11797)] [[Code](https://github.com/DMIRLAB-Group/SASA-pytorch)]

- <a name="Voice2Series"></a>  **[Voice2Series]** Voice2Series: Reprogramming acoustic models for time series classification: (**38th Int. Conf. Mach. Learn.**)[[Paper](https://arxiv.org/pdf/2106.09296)][[Code](https://github.com/huckiyang/Voice2Series-Reprogramming)]

- <a name="Autoformers"></a>  **[Autoformer]** Autoformer: Decomposition transformers with autocorrelation for long-term series forecasting: (**Adv. Neural Inf. Process. Syst.**)[[Paper](https://arxiv.org/pdf/2106.13008)][[Code](https://github.com/thuml/Autoformer)]

- <a name="Transformers4MTS"></a>  **[Transformers4MTS]** A transformer-based framework for multivariate time series representation learning: (**27th ACM SIGKDD Conf. Knowl. Discov. Data Mining**)[[Paper](https://arxiv.org/pdf/2010.02803)][[Code](https://github.com/gzerveas/mvts_transformer)]

- <a name="TabFormer"></a>  **[TabFormer]** Tabular transformers for modeling multivariate time series: (**ICLR 2021**)[[Paper](https://arxiv.org/pdf/2011.01843v1)][[Code](https://github.com/IBM/TabFormer)]

- <a name="TERA"></a>  **[TERA]** TERA: Self-supervised learning of transformer encoder representation for speech: (**ICASSP 2021**)[[Paper](https://arxiv.org/pdf/2007.06028)][[Code](https://github.com/s3prl/s3prl)]

- <a name="DenseCL"></a>  **[DenseCL]** Dense contrastive learning for self-supervised visual pre-training: (**ICCV 2021**)[[Paper](https://arxiv.org/pdf/2011.09157)][[Code](https://github.com/WXinlong/DenseCL)]

- <a name="URL-TNC"></a>  **[URL-TNC]** Unsupervised representation learning for time series with temporal neighborhood coding: (**ICLR 2021**)[[Paper](https://arxiv.org/pdf/2106.00750)][[Code](https://github.com/sanatonek/TNC_representation_learning)]

- <a name="Informer"></a>  **[Informer]** Informer: Beyond efficient transformer for long sequence time-series forecasting: (**AAAI 2021**)[[Paper](https://arxiv.org/pdf/2012.07436)][[Code](https://github.com/zhouhaoyi/Informer2020)]

### 2020

- <a name="MSDDA-WS"></a>  **[MSDDA-WS]** Multi-source deep domain adaptation with weak supervision for time-series sensor data: (**Proc. 26th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining**)[[Paper](https://arxiv.org/pdf/2005.10996)][[Code](https://github.com/floft/codats)]

- <a name="Self-Time"></a>  **[Self-Time]** Self-supervised time series representation
learning by inter-intra relational reasoning: (**Under Review**)[[Paper](https://arxiv.org/pdf/2011.13548)][[Code](https://github.com/haoyfan/SelfTime)]

### 2019

- <a name="vq-wav2vec"></a>  **[vq-wav2vec]** vq-wav2vec: Self-supervised learning of discrete speech representations: (**34th Conference on Neural Information Processing Systems**)[[Paper](https://arxiv.org/pdf/1910.05453)][[Code](https://github.com/facebookresearch/fairseq)]

- <a name="BERT"></a>  **[BERT]** BERT: Pre-training of deep bidirectional transformers for language understanding:(**Proc. 2019 Conf. North Amer. Chapter Assoc. Comput. Linguistics: Hum. Lang. Technol.**)[[Paper](https://arxiv.org/pdf/1810.04805)][[Code](https://github.com/google-research/bert)]

- <a name="USRL-MTS"></a>  **[USRL-MTS]** Unsupervised scalable representation learning for multivariate time series: (**NeurIPS 2019**)[[Paper](https://arxiv.org/pdf/1901.10738)][[Code](https://github.com/White-Link/UnsupervisedScalableRepresentationLearningTimeSeries)]

- <a name="ELB-MB-Transformer"></a>  **[ELB-MB-Transformer]** Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting: (**NeurIPS 2019**)[[Paper](https://arxiv.org/pdf/1907.00235)][[Code](https://github.com/mlpotter/Transformer_Time_Series)]

### 2018

- <a name="TL4TSC"></a> **[TL4TSC]** Transfer Learning for Time Series Classification: (**2018 IEEE International Conference on Big Data**) [[paper](https://arxiv.org/pdf/1811.01533)][[code](https://github.com/hfawaz/bigdata18?tab=readme-ov-file)]

### 2016

- <a name="Audio Word2Vec"></a> **[Audio Word2Vec]** Audio Word2Vec: Unsupervised learning of audio segment representations using sequence-to-sequence autoencoder: (**IEEE International Conference on Acoustics, Speech, and Signal Processing**)[[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462332)][[code](https://github.com/jcvasquezc/DisVoice)]

### 2014

- <a name="Seq2Seq"></a> **[Seq2Seq]** Sequence to sequence learning with neural networks: (**Proc. Adv. Neural Inf. Process. Syst.**) [[paper](https://arxiv.org/pdf/1409.3215)][[code](https://github.com/farizrahman4u/seq2seq?tab=readme-ov-file)]
